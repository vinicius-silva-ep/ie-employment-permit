{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec7ec008",
   "metadata": {},
   "source": [
    "2018 - Employment Permit by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the raw data in the folder on my personal computer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r\"E:/My Drive/ESTUDOS DATA SCIENCE/ie-employment-permit/data/raw_data_before_2020/2018/permits-by-county-2018.xlsx\", # This case is using .xlsx and has a different file name, 2010 and 2009 were using the extension .xls\n",
    "                   skiprows=[1] # I needed to skip these rows because I had the summarization of the values by year (which was uninteresting) and one more row without any sense\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b614365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the NaN values by the year\n",
    "df[\"Year\"] = df[\"Year\"].fillna(\"2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before 2020 the column structures of the files were different. So, I needed to rename the column \"Total\" by \"Issued\" because after 2020 the new file didn't have the columns \"New\" and \"Renewals\", only \"Issued\". In this case, to keep the standard of the project, I needed to mantain only \"Issued\".\n",
    "df.rename(columns={\"Total\": \"Issued\", \"County/Country\": \"County\"}, inplace=True)\n",
    "df.drop(columns=[\"New\", \"Renewal\"], inplace=True)\n",
    "\n",
    "# I created the column \"Obs\" to make sure that all counties belong to Ireland or any issues that I could find by crossing some databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this part of project is focused only in the counties, I had to group all missed places by \"Others\"\n",
    "\n",
    "# I had to made a copy of the df with the filtered rows by not being \"NaN\" (because some cases are about countries or counties from North Ireland)\n",
    "df_others = df[df[\"Obs\"].notna()].copy()\n",
    "# Replacing all values by just \"Others\" to facilitate the analysis\n",
    "df_others[\"County\"] = \"Others\"\n",
    "# Summarizing the columns\n",
    "df_others_grouped = df_others.groupby([\"Year\", \"County\"], as_index=False)[[\"Issued\", \"Refused\", \"Withdrawn\"]].sum()\n",
    "# Creating a dataframe with only the \"Others\" row\n",
    "df_main = df[df[\"Obs\"].isna()].copy()\n",
    "# Concatenating both dataframes, original and the modified copy\n",
    "df = pd.concat([df_main, df_others_grouped], ignore_index=True)\n",
    "# As I don't need to use the \"Obs\" column, I removed for the final file\n",
    "df.drop(columns=[\"Obs\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used the extension .csv because is lighter and easy to work with some libraries like pandas, sqlalchemy\n",
    "df.to_csv(r\"E:/My Drive/ESTUDOS DATA SCIENCE/ie-employment-permit/data/2018/permits-issued-by-county-2018.csv\", index=False)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
